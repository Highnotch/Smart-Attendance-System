{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fcdac97-b91d-47fd-a8d5-d7a1e22f0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import face_recognition\n",
    "#import cv2\n",
    "#import os\n",
    "#import numpy as np\n",
    "#import pickle as pkl\n",
    "#import matplotlib.pyplot\n",
    "#import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aeb3f742-7c95-49a3-b8ec-92f5b32edfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images/sujith.jpg\")\n",
    "#starting counter \n",
    "#a=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50e0939f-76d6-47f7-a33e-61dbc2445d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_locations = face_recognition.face_locations(img)\n",
    "#b=time.time()\n",
    "#print(\"time taken to identify face locations \"+ str(b-a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d96e606-d9f4-460d-80c9-52496cb453b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_encodings = face_recognition.face_encodings(img, face_locations)\n",
    "#c=time.time()\n",
    "#print(\"time taken to encode faces \"+str(c-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f50910-c839-458d-824e-7f4a7bc540d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#known_names=os.listdir(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images\")\n",
    "#known_names.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9aec6318-e057-4855-b291-80d47a902784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#known_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d36b5ee-2762-44ff-8f72-9c24cb6e7eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images/data.pkl\"\n",
    "#face_pkl=open(filename,\"rb\")\n",
    "#known_data=pkl.load(face_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5437a137-a8b7-4e0d-9058-92f979b98079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recognised_faces=[]\n",
    "#for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#        # Try to match the face with the known faces\n",
    "#        matches = face_recognition.compare_faces(known_data, face_encoding)\n",
    "#        name = \"Unknown\"\n",
    "#\n",
    "#        # Find the best match\n",
    "#        face_distances = face_recognition.face_distance(known_data, face_encoding)\n",
    "#        best_match_index = np.argmin(face_distances)\n",
    "#        if matches[best_match_index]:\n",
    "#            name = known_names[best_match_index]\n",
    "#            recognised_faces.append(name)\n",
    "#print(recognised_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e5665-d9a1-4f80-a41d-eacc7d643077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d997bc5-f8c0-41fd-b275-e5d036af98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = r'/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images'\n",
    "#os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7eb2e9c8-453a-4960-b31d-66b1eb4dcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "#\n",
    "#videoCaptureObject = cv2.VideoCapture(0)\n",
    "#result = True\n",
    "#while(result):\n",
    "#    ret,frame = videoCaptureObject.read()\n",
    "#    cv2.imshow('Capturing Video',frame)\n",
    "#    cv2.imwrite(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/NewPicture.jpg\",frame)\n",
    "#    result = False\n",
    "#videoCaptureObject.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6c65f3b-6f5e-4b52-99e6-9513a181be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "############------------------ UPDATE-1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0fa8b86-7aa0-4b23-8059-0caa4315f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import time "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c036976f-cf5e-40a1-b7db-347bf4f39d4b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loading Pickle File For Know_Faces Data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2049ead0-18ab-41dc-a719-ac54e3244ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/data_home.pkl\"\n",
    "face_pkl=open(filename,\"rb\")\n",
    "known_data=pkl.load(face_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed4f0af8-1cb6-403e-8ad3-c3e628c3ccd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b2f4092-8451-4b34-9ef1-935377911d69",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Taking pictures from the camera  source and saving it in a directory .\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07c7fbc2-1aee-484a-9986-065a2d2e97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "escape hit, closing the app\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(0)\n",
    "# making the image count as zero initially\n",
    "\n",
    "img_counter = 0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print('failed to grab frame')\n",
    "        break\n",
    "    cv2.imshow('test', frame)\n",
    "    #to get continuous live video feed from my laptops webcam\n",
    "    k  = cv2.waitKey(1)\n",
    "    # Here the programe waits for the key to be pressed and return the key code \n",
    "    \n",
    "    # KEY CODE OF \"ESC\" is 27\n",
    "    \n",
    "    # KEY CODE OF \"Space\" is 32\n",
    "    \n",
    "    # SO , Therfore if the escape key is been pressed, the app will stop\n",
    "    \n",
    "    if k == 27:\n",
    "        print('escape hit, closing the app')\n",
    "        break\n",
    "    # if the spacebar key is been pressed\n",
    "    \n",
    "    # screenshots will be taken\n",
    "    \n",
    "    elif k  == 32:\n",
    "        \n",
    "        # the format for storing the images scrreenshotted\n",
    "        img_name =\"capture\"+str(img_counter)+\".jpg\"\n",
    "        loc=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/\"+img_name\n",
    "        # saves the image as a png file\n",
    "        cv2.imwrite(loc, frame)\n",
    "        print('screenshot taken')\n",
    "        # the number of images automaticallly increases by 1\n",
    "        img_counter += 1\n",
    "\n",
    "# release the camera\n",
    "cam.release()\n",
    "\n",
    "# stops the camera window\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a87b796f-d78c-40f3-8432-47fb971d4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "pic_all=glob.glob(os.path.join(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured\", '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c04bf3ac-100f-4970-a1d7-ac46ad6c27f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture7.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture6.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture4.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture5.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture1.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture0.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture2.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture3.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/capture8.jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d9831fe-e662-4e07-80e1-92337035c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_names=os.listdir(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Train\")\n",
    "known_names.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f1cd136-75c2-4d3f-aa42-c49b5e6778a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nanna.jpeg', 'Sujith.jpeg', 'madhavi.jpeg', 'nikhil.jpeg']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d413b33e-9fdd-4555-b7d2-5cb00957452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a8d1934-be9e-442d-a61d-cd9d4260a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognised_faces=[]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa92979-65e3-4831-b272-480b425f7f49",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### DRAWING A BOX AROUND FACES RECOGNISED IN THE PICTURE AND OUTPUTTING THE RECOGNISED FACES IN ALL THE IMAGES\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3af9efc-0d6b-46d9-98e9-4681452c1e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to identify face locations 1.2760961055755615\n",
      "time taken to encode faces 0.32770299911499023\n",
      " \n",
      "time taken to identify face locations 1.223564863204956\n",
      "time taken to encode faces 0.3051340579986572\n",
      " \n",
      "time taken to identify face locations 1.2317900657653809\n",
      "time taken to encode faces 0.3034389019012451\n",
      " \n",
      "time taken to identify face locations 1.2323336601257324\n",
      "time taken to encode faces 0.30269432067871094\n",
      " \n",
      "time taken to identify face locations 1.2261030673980713\n",
      "time taken to encode faces 0.3018369674682617\n",
      " \n",
      "time taken to identify face locations 1.2123138904571533\n",
      "time taken to encode faces 0.2984931468963623\n",
      " \n",
      "time taken to identify face locations 1.2157371044158936\n",
      "time taken to encode faces 0.30428385734558105\n",
      " \n",
      "time taken to identify face locations 1.230997085571289\n",
      "time taken to encode faces 0.30345702171325684\n",
      " \n",
      "time taken to identify face locations 1.2197191715240479\n",
      "time taken to encode faces 0.30370092391967773\n",
      " \n",
      " \n",
      " \n",
      "['Sujith.jpeg', 'nikhil.jpeg', 'Nanna.jpeg']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in pic_all:\n",
    "    #starting counter \n",
    "    a=time.time()\n",
    "    img=cv2.imread(i)\n",
    "    \n",
    "    \n",
    "    face_locations = face_recognition.face_locations(img)\n",
    "    b=time.time()\n",
    "    print(\"time taken to identify face locations \"+ str(b-a))\n",
    "    \n",
    "    \n",
    "    face_encodings = face_recognition.face_encodings(img, face_locations,num_jitters=5)\n",
    "    c=time.time()\n",
    "    print(\"time taken to encode faces \"+str(c-b))\n",
    "    print(\" \")\n",
    "    img_counter=0\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        # Try to match the face with the known face\n",
    "        matches = face_recognition.compare_faces(known_data, face_encoding,tolerance=0.5)\n",
    "        #name = \"Unknown\"\n",
    "\n",
    "        # Find the best match\n",
    "        face_distances = face_recognition.face_distance(known_data, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "            recognised_faces.append(name)\n",
    "            top, right, bottom, left = face_location\n",
    "            cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv2.putText(img, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 1)\n",
    "            cv2.imshow(\"out\",img)\n",
    "            img_name =\"capture\"+str(img_counter)+\".jpg\"\n",
    "            saved=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Detected/\"+img_name\n",
    "            img_counter=img_counter+1\n",
    "            cv2.imwrite(saved,img)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "unique_faces=list(set(recognised_faces))\n",
    "#print(recognised_faces)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(unique_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5776754-7f89-4b62-977c-bf478e2128af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sujith.jpeg',\n",
       " 'nikhil.jpeg',\n",
       " 'Sujith.jpeg',\n",
       " 'nikhil.jpeg',\n",
       " 'nikhil.jpeg',\n",
       " 'Nanna.jpeg',\n",
       " 'Sujith.jpeg',\n",
       " 'Sujith.jpeg',\n",
       " 'nikhil.jpeg',\n",
       " 'Nanna.jpeg',\n",
       " 'Sujith.jpeg',\n",
       " 'Nanna.jpeg',\n",
       " 'nikhil.jpeg',\n",
       " 'Nanna.jpeg',\n",
       " 'Sujith.jpeg',\n",
       " 'nikhil.jpeg',\n",
       " 'Nanna.jpeg',\n",
       " 'nikhil.jpeg',\n",
       " 'Sujith.jpeg',\n",
       " 'nikhil.jpeg',\n",
       " 'Nanna.jpeg',\n",
       " 'Sujith.jpeg',\n",
       " 'Nanna.jpeg',\n",
       " 'Sujith.jpeg',\n",
       " 'nikhil.jpeg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognised_faces"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a566440-93e5-4f6f-bf9b-5eee88747c54",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "# DETECTING ALL FACES IN THE FRAME \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acc69707-8c84-44a4-b980-99c18167d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to identify face locations 1.114548921585083\n",
      "time taken to encode faces 1.14182710647583\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in pic_all:\n",
    "    #starting counter \n",
    "    a=time.time()\n",
    "    img=cv2.imread(i)\n",
    "    \n",
    "    \n",
    "    face_locations = face_recognition.face_locations(img)\n",
    "    b=time.time()\n",
    "    print(\"time taken to identify face locations \"+ str(b-a))\n",
    "    \n",
    "    \n",
    "    face_encodings = face_recognition.face_encodings(img, face_locations,num_jitters=5)\n",
    "    c=time.time()\n",
    "    print(\"time taken to encode faces \"+str(c-b))\n",
    "    print(\" \")\n",
    "    img_counter=0\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        # Try to match the face with the known faces\n",
    "        matches = face_recognition.compare_faces(known_data, face_encoding,tolerance=0.5)\n",
    "        #name = \"Unknown\"\n",
    "\n",
    "        # Find the best match\n",
    "        face_distances = face_recognition.face_distance(known_data, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        #if matches[best_match_index]:\n",
    "        name = known_names[best_match_index]\n",
    "        recognised_faces.append(name)\n",
    "        top, right, bottom, left = face_location\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        #cv2.putText(img, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 1)\n",
    "        cv2.imshow(\"out\",img)\n",
    "        img_name =\"capture\"+str(img_counter)+\".jpg\"\n",
    "        saved=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Detected/\"+img_name\n",
    "        img_counter=img_counter+1\n",
    "        cv2.imwrite(saved,img)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2821c746-1fc9-4ed8-ab98-0e262f102d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aman_min.jpg', 'bhunia-min.jpg', 'sujith-min.jpg']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognised_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53478d3d-1bc7-4c23-87ed-46bc93d5357d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
