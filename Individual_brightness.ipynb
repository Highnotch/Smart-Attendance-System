{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa8b86-7aa0-4b23-8059-0caa4315f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfbbab6-7712-4055-835d-bdff8e1ed581",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loading Pickle File For Know_Faces Data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049ead0-18ab-41dc-a719-ac54e3244ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/junior_data_230.pkl\"\n",
    "face_pkl_230=open(filename,\"rb\")\n",
    "known_data_1=pkl.load(face_pkl_230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c3d638-0622-4b7d-aee9-2443a888fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/junior_data_remain.pkl\"\n",
    "face_pkl_remain=open(filename,\"rb\")\n",
    "known_data_2=pkl.load(face_pkl_remain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516d3e8-3f01-4083-9423-501ff33d5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in known_data_2:\n",
    "    known_data_1.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b20d3-e6eb-4873-85a6-e13b0e5f11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_data=known_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f0af8-1cb6-403e-8ad3-c3e628c3ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(known_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878155f-981c-4e70-89e7-e011997e5d54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Taking pictures from the camera  source and saving it in a directory .\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7fbc2-1aee-484a-9986-065a2d2e97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(0)\n",
    "# making the image count as zero initially\n",
    "\n",
    "img_counter = 0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print('failed to grab frame')\n",
    "        break\n",
    "    cv2.imshow('test', frame)\n",
    "    #to get continuous live video feed from my laptops webcam\n",
    "    k  = cv2.waitKey(1)\n",
    "    # Here the programe waits for the key to be pressed and return the key code \n",
    "    \n",
    "    # KEY CODE OF \"ESC\" is 27\n",
    "    \n",
    "    # KEY CODE OF \"Space\" is 32\n",
    "    \n",
    "    # SO , Therfore if the escape key is been pressed, the app will stop\n",
    "    \n",
    "    if k == 27:\n",
    "        print('escape hit, closing the app')\n",
    "        break\n",
    "    # if the spacebar key is been pressed\n",
    "    \n",
    "    # screenshots will be taken\n",
    "    \n",
    "    elif k  == 32:\n",
    "        \n",
    "        # the format for storing the images scrreenshotted\n",
    "        img_name =\"capture\"+str(img_counter)+\".jpg\"\n",
    "        loc=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/\"+img_name\n",
    "        # saves the image as a png file\n",
    "        cv2.imwrite(loc, frame)\n",
    "        print('screenshot taken')\n",
    "        # the number of images automaticallly increases by 1\n",
    "        img_counter += 1\n",
    "\n",
    "# release the camera\n",
    "cam.release()\n",
    "\n",
    "# stops the camera window\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f1b493-089d-4f2b-beb0-c376e791ec8c",
   "metadata": {},
   "source": [
    "## Individual face brightness increasing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c045917-3aa3-4bc7-a3c4-8d37778f41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread('/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/test.jpg')\n",
    "\n",
    "# Detect face locations in the image\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "def check_dullness(image):\n",
    "    \n",
    "    # Calculating the average pixel intensity of the image\n",
    "    average_intensity = cv2.mean(image)[0]\n",
    "    \n",
    "    # Setting  a threshold for dullnessss\n",
    "    threshold = 200  \n",
    "    \n",
    "    if average_intensity < threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Adjust brightness and contrast for each detected face\n",
    "for face_location in face_locations:\n",
    "    top, right, bottom, left = face_location\n",
    "\n",
    "    # Extract the face region\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    if check_dullness(face_image)==True:\n",
    "        alpha=1.2  # Brightness adjustment (1.0 means no change)\n",
    "        beta=20    # Contrast adjustment (0 means no change)\n",
    "        adjusted_image = cv2.convertScaleAbs(face_image, alpha=alpha, beta=beta)\n",
    "        image[top:bottom, left:right] = adjusted_image\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "\n",
    "    # Increase brightness and contrast of the face image\n",
    "    #alpha = 1.2  # Brightness adjustment (1.0 means no change)\n",
    "    #beta = 25  # Contrast adjustment (0 means no change)\n",
    "    #adjusted_image = cv2.convertScaleAbs(face_image, alpha=alpha, beta=beta)\n",
    "\n",
    "    # Replace the original face region with the adjusted image\n",
    "    #image[top:bottom, left:right] = adjusted_image\n",
    "\n",
    "# Display the modified image\n",
    "#cv2.imshow(\"Modified Image\", image)\n",
    "cv2.imwrite('/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/test.jpg',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b796f-d78c-40f3-8432-47fb971d4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "pic_all=glob.glob(os.path.join(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured\", '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bf3ac-100f-4970-a1d7-ac46ad6c27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027f27c-56ec-474b-8449-9beb83d058bd",
   "metadata": {},
   "source": [
    "## Dont Run Below \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f70527-aefb-4a8a-9331-aa5f05874893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def adjust_brightness_contrast(image, brightness=0, contrast=0):\n",
    "    # Apply brightness and contrast adjustments\n",
    "    adjusted_image = cv2.convertScaleAbs(image, alpha=contrast, beta=brightness)\n",
    "    return adjusted_image\n",
    "\n",
    "def check_dullness(image):\n",
    "    \n",
    "    # Calculating the average pixel intensity of the image\n",
    "    average_intensity = cv2.mean(image)[0]\n",
    "    \n",
    "    # Setting  a threshold for dullnessss\n",
    "    threshold = 200  \n",
    "    \n",
    "    if average_intensity < threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "count=0\n",
    "for image_path in pic_all:\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "# Checking if the image is dull or not!!!\n",
    "    if check_dullness(image):\n",
    "    # Adjust brightness and contrast\n",
    "        adjusted_image = adjust_brightness_contrast(image, brightness=10, contrast=1.1)\n",
    "    #cv2.imshow('Original Image', image)\n",
    "        cv2.imshow('Adjusted Image', adjusted_image)\n",
    "        cv2.imwrite(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/\"+str(count)+\".jpg\",adjusted_image)\n",
    "        count=count+1\n",
    "    \n",
    "    #cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"The image is not dull.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dadc32f-1b5d-4614-9eb0-677576cfaba9",
   "metadata": {},
   "source": [
    "## Till Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9831fe-e662-4e07-80e1-92337035c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_names_1=os.listdir(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/images_230\")\n",
    "#known_names_1.remove(\".DS_Store\")\n",
    "known_names_2=os.listdir(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/images_remain\")\n",
    "#known_name_2.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1cd136-75c2-4d3f-aa42-c49b5e6778a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_names=known_names_1+(known_names_2)\n",
    "known_names.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413b33e-9fdd-4555-b7d2-5cb00957452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(known_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d1934-be9e-442d-a61d-cd9d4260a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognised_faces=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f36342-b860-44d3-8609-643a26122dc7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### DRAWING A BOX AROUND FACES RECOGNISED IN THE PICTURE AND OUTPUTTING THE RECOGNISED FACES IN ALL THE IMAGES\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af9efc-0d6b-46d9-98e9-4681452c1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_counter=0\n",
    "for i in pic_all:\n",
    "    #starting counter \n",
    "    a=time.time()\n",
    "    img=cv2.imread(i)\n",
    "    \n",
    "    \n",
    "    face_locations = face_recognition.face_locations(img)\n",
    "    b=time.time()\n",
    "    print(\"time taken to identify face locations \"+ str(b-a))\n",
    "    \n",
    "    \n",
    "    face_encodings = face_recognition.face_encodings(img, face_locations,num_jitters=6)\n",
    "    c=time.time()\n",
    "    print(\"time taken to encode faces \"+str(c-b))\n",
    "    print(\" \")\n",
    "#changing here    img_counter=0\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        # Try to match the face with the known face\n",
    "        matches = face_recognition.compare_faces(known_data, face_encoding,tolerance=0.5)\n",
    "        #name = \"Unknown\"\n",
    "\n",
    "        # Find the best match\n",
    "        face_distances = face_recognition.face_distance(known_data, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "            recognised_faces.append(name)\n",
    "            top, right, bottom, left = face_location\n",
    "            cv2.rectangle(img, (left+2, top+2), (right+2, bottom+2), (255, 0, 0), 4)\n",
    "            cv2.putText(img, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 255), 2)\n",
    "            cv2.imshow(\"out\",img)\n",
    "            img_name =\"capture\"+str(img_counter)+\".jpg\"\n",
    "            saved=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Detected/\"+img_name\n",
    "            img_counter=img_counter+1\n",
    "            cv2.imwrite(saved,img)\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "unique_faces=list(set(recognised_faces))\n",
    "#print(recognised_faces)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(unique_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5776754-7f89-4b62-977c-bf478e2128af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recognised_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74114c02-b3c3-4805-baaa-909aa7b61713",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72939e63-91e6-4420-8b47-7714cd9de9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/test.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840b54c-9846-4a79-bc57-45d593793b3a",
   "metadata": {},
   "source": [
    "## This code is for increasing brightness and contrast of coimplete picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964d91e-954f-4eb2-a7f4-4d51861567da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness_contrast(image, brightness=0, contrast=0):\n",
    "        # Apply brightness and contrast adjustments\n",
    "        adjusted_image = cv2.convertScaleAbs(image, alpha=contrast, beta=brightness)\n",
    "        return adjusted_image\n",
    "\n",
    "def check_dullness(image):\n",
    "    \n",
    "        # Calculating the average pixel intensity of the image\n",
    "    average_intensity = cv2.mean(image)[0]\n",
    "    \n",
    "        # Setting  a threshold for dullnessss\n",
    "    threshold = 200  \n",
    "    \n",
    "    if average_intensity < threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "for j in range(len(face_locations)):\n",
    "    top, right, bottom, left = face_locations[j]\n",
    "    face_image=image[top:bottom,left:right]\n",
    "    #face_only = Image.fromarray(face_image)\n",
    "    count=0\n",
    "    \n",
    "\n",
    "# Checking if the image is dull or not!!!\n",
    "    if check_dullness(face_image):\n",
    "    # Adjust brightness and contrast\n",
    "        adjusted_image = adjust_brightness_contrast(image, brightness=10, contrast=1.1)\n",
    "    #cv2.imshow('Original Image', image)\n",
    "        cv2.imshow('Adjusted Image', adjusted_image)\n",
    "        cv2.imwrite(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/\"+str(count)+\".jpg\",adjusted_image)\n",
    "        count=count+1\n",
    "    \n",
    "    #cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"The image is not dull.\")\n",
    "    \n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efeba1f-71c9-4892-86f3-2c199f6a8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "for items in recognised_faces:\n",
    "    freq[items] = recognised_faces.count(items)\n",
    "    \n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c86969-68b5-421a-99db-831f1bfa3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_att={}\n",
    "for i in freq.keys():\n",
    "    if (freq[i]>0.5*(len(pic_all))):\n",
    "        final_att[i]=freq[i]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b36ce9-93d2-47fe-9b5f-eea7abaacd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d3989-461c-4a51-827c-0b56b95a7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_attendance=list(final_att.keys())\n",
    "len(final_attendance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a9787-d5d7-4d2a-bb12-b630507164e9",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "# DETECTING ALL FACES IN THE FRAME \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc69707-8c84-44a4-b980-99c18167d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in pic_all:\n",
    "    #starting counter \n",
    "    a=time.time()\n",
    "    img=cv2.imread(i)\n",
    "    \n",
    "    \n",
    "    face_locations = face_recognition.face_locations(img)\n",
    "    b=time.time()\n",
    "    print(\"time taken to identify face locations \"+ str(b-a))\n",
    "    \n",
    "    \n",
    "    face_encodings = face_recognition.face_encodings(img, face_locations,num_jitters=5)\n",
    "    c=time.time()\n",
    "    print(\"time taken to encode faces \"+str(c-b))\n",
    "    print(\" \")\n",
    "    img_counter=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        # Try to match the face with the known faces\n",
    "        matches = face_recognition.compare_faces(known_data, face_encoding,tolerance=0.5)\n",
    "        #name = \"Unknown\"\n",
    "\n",
    "        # Find the best match\n",
    "        face_distances = face_recognition.face_distance(known_data, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        \n",
    "        \n",
    "        #if matches[best_match_index]:\n",
    "        name = known_names[best_match_index]\n",
    "        \n",
    "        \n",
    "        recognised_faces.append(name)\n",
    "        top, right, bottom, left = face_location\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        #cv2.putText(img, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 1)\n",
    "        \n",
    "        \n",
    "        cv2.imshow(\"out\",img)\n",
    "        img_name =\"capture\"+str(img_counter)+\".jpg\"\n",
    "        saved=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Detected/\"+img_name\n",
    "        img_counter=img_counter+1\n",
    "        cv2.imwrite(saved,img)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821c746-1fc9-4ed8-ab98-0e262f102d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognised_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53478d3d-1bc7-4c23-87ed-46bc93d5357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=known_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64670755-1829-4353-923b-8787c08f3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394694b-cb1d-4345-899f-0ade85d31d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de04a4a-285f-4d1b-8815-63df2e9fcc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36aee5-192f-4b05-bce1-14206497a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670703c-9bb7-4b7a-81bb-3696fc6650b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc00d2-fb6b-464a-a498-998869ea9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ad0b6-038b-456d-9a3e-6798647f5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91458e82-9ce5-4fa9-8aab-eb30b2436bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
